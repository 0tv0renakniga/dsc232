### 8.3_notebook.md

```markdown
# Principal components analysis

```python
%pylab inline
import pandas as pd
from numpy import arange,array,ones,linalg
import warnings
warnings.filterwarnings("ignore")
"""
RETURNS ->

%pylab is deprecated, use %matplotlib inline and import the required libraries.
Populating the interactive namespace from numpy and matplotlib
"""

```

## Small example

Suppose we have 9 points on the plane, defined by their  coordinates

```python
data = array([
    [ 2.4,  0.7],
    [ 2.9, -0.7],
    [ 2.2, -1.6],
    [ 3. ,  1.2],
    [ 2.4, -0.2],
    [ 4.6,  1.1],
    [ 2.3, -2.1],
    [ 0.7, -1.3],
    [ 1.1, -0.2]])
plt.scatter(data[:,0],data[:,1])
plt.xlim(-10,10); plt.ylim(-10,10)
plt.title('original data')
grid()
"""
RETURNS ->

[Plot/Image Output: Scatter plot of original data]
"""

```

### PCA - step by step

#### 1. Mean centering

We first subtract the mean from each coordinate to center the data around the origin.

```python
mn=mean(data,axis=0)
data-=mn
plt.scatter(data[:,0],data[:,1])
plt.xlim(-4,4); plt.ylim(-4,4)
plt.title('Mean centered data')
grid()
"""
RETURNS ->

[Plot/Image Output: Scatter plot of mean centered data]
"""

```

#### 2. Covariance matrix

We calculate the covariance matrix of the data.



where  is the data matrix (n samples x d features).

```python
C = cov(data.T)
print(C)
"""
RETURNS ->

[[1.26763889 0.73902778]
 [0.73902778 1.41111111]]
"""

```

#### 3. Eigen decomposition

We compute the eigenvalues and eigenvectors of the covariance matrix.

```python
evals,evecs=linalg.eig(C)
print("Eigenvalues:",evals)
print("Eigenvectors:\n",evecs)
"""
RETURNS ->

Eigenvalues: [0.59726978 2.08148022]
Eigenvectors:
 [[-0.74106918 -0.67142751]
 [ 0.67142751 -0.74106918]]
"""

```

#### 4. Projection

The principal components are the eigenvectors corresponding to the largest eigenvalues.
We can project the data onto the principal components to reduce dimensionality.

```python
# Sort by eigenvalue in descending order
idx = argsort(evals)[::-1]
evecs = evecs[:,idx]
evals = evals[idx]

print("Sorted Eigenvalues:",evals)
print("Sorted Eigenvectors:\n",evecs)

# Project data
projected_data = dot(data, evecs)

plt.scatter(projected_data[:,0],projected_data[:,1])
plt.xlim(-4,4); plt.ylim(-4,4)
plt.title('Data projected onto PC1 and PC2')
grid()
"""
RETURNS ->

Sorted Eigenvalues: [2.08148022 0.59726978]
Sorted Eigenvectors:
 [[-0.67142751 -0.74106918]
 [-0.74106918  0.67142751]]
[Plot/Image Output: Scatter plot of projected data]
"""

```

### Explanation

* The **first principal component** (PC1) corresponds to the direction of maximum variance in the data.
* The **second principal component** (PC2) is orthogonal to PC1 and captures the remaining variance.
* The **eigenvalues** indicate the amount of variance explained by each principal component.

```python
var_explained = evals / sum(evals)
print("Variance explained by PC1:", var_explained[0])
print("Variance explained by PC2:", var_explained[1])
"""
RETURNS ->

Variance explained by PC1: 0.7770172605886616
Variance explained by PC2: 0.2229827394113384
"""

```

```

```
