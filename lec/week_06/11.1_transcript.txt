(upbeat music) - [Instructor] Hi, we're
going to start talking about classification machine
learning mechanisms. So, different ways of
developing classifiers. So, we're going to start
with one of the simplest and most commonly used,
which is decision trees. So, here is an example of a decision tree. Let's say the thing that we're trying to classify is fun versus not fun. So, this is the data that we have. We have the season, summer or winter. And we have the location, which can be prison or beach or ski slope. So, and this is the data that we have. We want to fit a classification
rule to this data. So, we start, maybe, with
checking the location. So, we say, what is the
effect of the location? The location can be
prison, beach or ski slope. And then, if it's prison, it's
definitely going to be bad. If it's the beach, if it's a ski slope, it's always going to be good. But if it's the beach,
maybe we're not so sure. If it's the beach, it can be good or bad because of what we see here or here. So, for the beach, we need
to also check the season. So, we check the season. And if the season is winter, it's not fun. And if it's summer, it is fun. So, now we have a classification rule that captures all of this data and hopefully generalizes to new data. So, this is when the features that we're looking at
are discrete features. So, they can only take
one of a few values. Here, minus one or plus one for the fun. Location is prison, beach or ski slope. And season is summer or winter. Let's look at something more. That is decision trees when
you have continuous features. So, the question here is,
will the bomb explode? Let's see what we know about the bomb. We have the mass of the bomb. So, 1, 3.4, 10 or 11.5 pounds, let's say. And then temperature is
100, 945, 32 or 1202. So, of course, we can
treat these as discrete. But then we will have, for each example, it will fit only one discrete possibility. So, that's not going to be a small, succinct rule that will generalize well. So, we want a rule that will be a good rule for continuous variables. And so, let's say the first
thing that we check is the mass, whether the mass is larger than 8 or not. If the mass is smaller than 8, then no, because both of these, you have minus 1. If it is larger than 8, then we need to check the temperature. Right, so then if it's larger
than 8, it's this or this. And we need to see if the
temperature is larger than, let's say, 500. Then we can predict yes or no, whether it will explode or not. Okay, so the only difference
that is here is that here we're using comparators rather than
saying equal or not equal. And that is what gives us the
ability to, in a succinct way, describe, use the features
that are continuous. So, one way to visualize decision trees, if you have just two variables, which is not a common case, but it's a case that helps the intuition, is that you split your xy
plane according to the rule. so if this is x larger than 3, then this first rule is x
larger than 3 or smaller than 3. Here is, the yes is
here, and the no is here. So, what we get is that
at not larger than 3, we get minus 1. And at larger than 3, now
we check y, y larger than 5. So, this is when y larger than 5, and now we have minus 1 or plus 1. So, what we have here is a
way of partitioning the plane, or in general, Euclidean space, using what is called
axis parallel hyperplane. So, we're separating things only according to inequality with one of the variables. So, why are decision trees so popular? One of the reasons is that
they're very flexible. They can be used to model
many different things, and they're easy to interpret. So, you can put a small
decision tree on a slide and show it to even people that don't know much about machine learning, and they will make sense of it. Learning a decision tree is finding a tree with small error on the training set, and the way that we do it is that we build incrementally from the root node. And at each step, we have
a tree with some leaves, and we decide on which leaf
to split and how to split it. And we repeat until we reach
some termination criteria. Okay. So, how do we decide which node to split? So, we want the children to
be more pure than the parent. If the parent was 30% plus and 70% minus, we would prefer that the child, one child, will be maybe 95% plus, and the other child will
be 50% or 60% minus. So, now they are more pure, and they have more information
to tell us about the label. So, for example, suppose
the parent is 50-50%, and the child are 90-10 and 10-90. So, in this case, it's clear
that this is a good split, because now on each side we
know the actual label with 90%, while before we knew only with 50%. So, how can we quantify
this improvement in purity? Now we need some quantity
to measure the purity so that we can basically
write an algorithm for deciding which leaf to split. So, a naive approach might say you just want to minimize the
training error, right? So, in the case 50-50 to 90-10, 10-90, we moved from error of
50% to error of 10%, which is clearly an improvement. But it doesn't always work. Like, in this case here, it will work. So, parent node is 55 plus 45 minus, then predict plus always, and error is 45. Child nodes are 90-10, 10-90, and so they predict plus on
left and minus on the right, and the error is 10%. So, in this case, just looking at the training
error of the larger tree gives us a good sense that
this is an improvement. But here is a case that
there isn't improvement. So, the parent node,
let's say, is 80% and 20%, and you always predict
plus, so the error is 20%. And the child nodes are
now 90%, 10%, and 70%, 30%. So, 90% on the plus and 70% of the plus. So, what does that mean? It means that in either
leaf, we will predict plus. And what is the error now? It's still 20%. So, the error was 20%. The old error was 20%. So, it seems like we didn't
make any improvement. In fact, we did make some improvement. Like, this one is more accurate, more higher percent of plus, and this has lower percent of plus, but it's not enough to
improve the training error. So, one way to think about this is to plot the probability
of plus as the axis here, from 0 to 1, and plot the error, the training error, as number from 0 to 0.5 here. The error cannot be more than 0.5 because you always go with a heavy side. So, it's at most 50%. Here, we have just what
the training error is for using the training error. And so, what we see is that
if we use a training error and we have two things that
are on the same side of 50%, then we don't really get an
improvement in the performance. But what we can do is we
can use another measure, instead of measuring error p, which is the minimum of p and 1 minus p, we measure the entropy of p. And that is this green
line that we have here. So, if we use the green line, then we get an improvement, even though they are
both on the same side. So, this point here is
above the linear combination of the two endpoints. So, if we use entropy
instead of training error, that basically gives us a way to improve, even if the training
error does not improve. And there are different
functions like that that have been used. So, what you need is a
function that is strictly concave and larger than the... it's an upper bound on the training error, so that if you minimize this function, one of these functions, you also minimize the training error, but because they are concave, they don't suffer from this problem of not seeing any improvement. And so, three that are
commonly used are the entropy that we talked about, the circle, which has some optimality properties, and then the Gini index, which
is simply p times 1 minus p. And different software
uses different ones, and it does not seem in general that there is a big difference between using different
functions like that. So, the question here is, which function of these
functions is strictly concave? So, this red function
is clearly not, right? This blue function seems strictly concave, but it has this straight
line here, so it's not. Only the green line, the green
curve, is strictly concave. Okay, so how does the decision
tree learning algorithm work? We have a measure that lets us measure how much of an improvement adding a particular split to
a leaf in the tree gives us. So, learning a decision tree means finding a tree with small
error on the training set. You start with a root node. At each node, at each step, you split one of the leaves, so you choose one of the leaves to split, and then you repeat until
a termination criteria. Okay, so which one do you split? Okay, so what you basically do in general is that you do a greedy search. You look at all possible new splits, and you measure the improvement due to it, and you just take the best one. So, you have the current tree. For each leaf and each feature, you find all possible splitting rules. So, you basically take each feature and split according to that feature, and then you do that
specifically for each leaf and for each feature. So, that seems like it
might take a long time, but in fact, this is
a very efficient thing that can be done very quickly, even for pretty large data. Compute reduction in entropy, and find the leaf and the
feature and the split rule that minimizes the entropy, and then you add it. So, how do you enumerate splitting rules? So, if the feature has a
fixed small number of values, then you can either split
on all values, okay, or you can split on equality
to a particular value, right? So, in the location, we
split into three children, but another option is to split just binary for equality to one of the features. In either case, there are
not that many possibilities. If the feature is continuous,
let's say temperature, then you either sort the
records by feature value and search for the best split, or you split on percentiles. So, here we'll come back to
the big data aspect of things. Sorting is a reasonably good approach if you have something like
10,000 or 100,000 examples, but if you have many millions of examples, then that becomes an expensive step, and as a matter of fact, you don't really care to split
after each possible value. It's quite enough to have 100 splits at the 100 percentile points. So, what does that mean? So, suppose there is data in an RDD with 100 million examples. Sorting is very expensive. It's a shuffle. You need to move data
from between workers. Instead, you take a sample, okay, so some small percentage, to get a sample of about 10,000 examples from all of your data, and based on that, you sort the sample and you select the thresholds
that you would want to use in order to split on each feature. So, for each feature,
you generate 100 values, and then you broadcast these 100 values to all of the workers. So, each partition
computes its contribution to this probability of plus one given between threshold
one and threshold two. If you get these 101 numbers, then you can, at the head
node, quickly compute the entropy for each
one of the thresholds. So, to summarize, the splitting criteria is
a strictly concave function that bounds the training error. The search for splitting rule tests all possible splits of the current tree, and when the feature is
continuous, the data is large, we split on percentiles instead of splitting on each example. Next, we're going to talk
about the performance on the test data and reducing overfitting. I'll see you soon.