(light music) (air whooshing) - Let's talk a little bit about the principles or tricks that you can use to make code run faster, specifically code that
is data analysis code. So suppose you have some program that you wrote in Python. And when you run it on a thousand data points, it takes two seconds to run and you're happy with that. But now, you want to run the same program on something like 1 billion points. So you don't want to wait for a million times longer than for the thousand points. And so how would you accelerate the code? And so how would you accelerate the code? So I'm going to talk
about two basic tricks. One is called using an efficient library or vectorizing and the other is the difference based on the difference between
latency and throughput. So regarding fast libraries, suppose we have a program that is doing regression or is training a deep neural network. The engine behind it, underneath it is linear algebra. And we can code this linear algebra in pure Python and that would work but that would be much, much slower than if we use a call to the NumPy library, okay? If the NumPy library has this operation that we want to do in linear algebra, then it would typically do it about a thousand times
faster than pure Python. So NumPy gives you the speed that you expect from code maybe in C++ or from Matlab. And the reason that it gives you the same speed as Matlab is that they both use similar libraries is that they both use similar libraries of optimized code and such a library, for instance, is LAPACK. That is a code base that has been released for the first time in 1992, 30 years ago, but it's still one of the most optimized code for specific computer architectures. So this code is available free of charge and basically is written in Fortran and it's constantly being optimized. So here is an example of what you might want to do. So suppose you want to multiply two matrices A and B and that basically means that you want to take each row here and multiply it by the column here. Take the dot product with a column, okay? And that would give you one element of the result matrix, okay? So you need to do that m times p times and each one of these
operations is m times. So you have the same operations of taking product and adding, but that you have to do it many, many times, okay? And fundamentally, this is the operation that you're doing but the question is, can you do these operations
really efficiently in the computer memory? So here is a little bit of code that is available to you in this notebook. And there are two matrices, A and B that are about a hundred by a hundred each. And you just want to
take the multiplication. So if you just do it with NumPy, that's the dot product operation. It takes about... 370 or 400 microsecond. So about half a millisecond, okay? And if you do it in native Python, then you basically need to write these loops that would perform the summation to generate the final matrix. So these embedded loops in Python are done not in the most efficient way. And therefore, the time that it takes to do that here is 65.5 or 519 millisecond, okay? So about half a second which is about a thousand times slower than the NumPy method. Okay, now, for the second part, big data basically starts when your data cannot fit into the memory of one computer. So suppose we still want to do something like the linear algebra but we cannot fit the whole data into the computer. And then basically, what is the bottleneck is bringing the data from disk to the computer. And that brings us to throughput versus a latency. So what are these two things? I'll first define them and then give you some examples. So throughput is the number of bytes that you process per second. So you process maybe
one gigabyte per second and that can benefit from parallelism because if your machine can do one gigabyte per second, then a hundred machine can maybe do 100 gigabyte per second. And it benefits also from processing big chunks of data rather than doing the data one by one. And this is the kind of thing that we really care about in data science, the throughput. How much data we can process per second? Latency is a different thing. It's basically the time that it takes from an input to an output. So if we give the computer an input, what output it generates? And that doesn't benefit from parallelism because if you have another computer, it doesn't make the computation any faster and the latency any smaller and it doesn't benefit from processing big blocks of data. But it is important in other things. It's important for anything
that is interactive. If you give some command to the computer, you're playing a computer game, you want the reaction
to be very, very fast like fraction of a second, right? And similarly, if you're
doing data analysis and you're hitting a key and you want to get a nice graph, you hope that this graph can be given to you as a matter of fraction of a second. So let's think about latency and throughput in the context of a store where people are going to the cashier. They join the line, a queue to one of the cashiers and then they wait in line until they get to the front and then the cashier sums their purchases and then the cashier sums their purchases and they pay and then they leave, okay? So in this context, latency is the time between the moment you joined the queue and the moment that you
exit the store, okay? So how long did you need to spend in processing that? And remember, the part that you're doing in the queue is part of it. That's part of how of the time that it takes you to process your purchases. Throughput on the other hand, is a different quantity. It's a quantity that says, if I look at the exit from the store, how many people are leaving per minute? So latency here has a minimum possible which is that there's no queue and you just have the cashier process your purchases. That's the minimum that you can expect. And in general, the customer really cares about the latency. You care about how long will it take you to wait in line. The store mostly cares about the throughput which basically means how many people are processed. But of course, they also want to keep the latency reasonable so people don't just leave in frustration. And because if they don't
have enough cashiers, the lines will just grow and grow and grow and grow, right? So they don't want that. They want basically the lines to be stable so that people basically can expect to leave the store in a reasonable amount of time. So what is latency and throughput for big data? Suppose we have one terabyte on disk. The data is basically a sequence of floating point numbers. And what we want to do is just sum the numbers and sum the square of the numbers. That's something that we
will actually want to do. And the question is, how fast can we do it? So it turns out that in a typical computer, the amount of time that it would take you to read the information from the disk and put it in memory is dominating the amount of time to do the actual computation. So basically, the CPU
is just sitting there waiting for data. So if you have 200 megabytes per second that you can get, then a gigabyte will
take you five seconds. And if one terabyte is 5,000 seconds, that will take about 1.4 hours, okay? So that's a long time to do this simple operation. But now, suppose that you
have a hundred machines, they're all exactly like
the original machines but each one of them has a separate disk with part of the data. And then you basically just have all of these machines compute these sums in parallel. And then at the end, you just combine the sums, okay? So this is a perfect throughput increasing operation. And you can do now the one terabyte in 50 seconds instead of 1.4 hours. Okay, so MapReduce, which we're going to talk about and Spark are ways of organizing
this kind of computation. So basically in a way that is transparent to you. It will basically compute the sum in parallel way on all of these machines. Okay, so to summarize, how do we increase
throughput for big data? The bottleneck is usually moving of data, not the computation itself. In terms of hardware, it's better to have many cheap, slow and unreliable computers than to have a few super fast and expensive and reliable computers. So the question is, how do you organize such a cluster of less reliable computers? And MapReduce and Hadoop and Spark are basically methods or methodologies for organizing a computation in these kind of large, unreliable computer clusters, okay? So that's it for this little video.